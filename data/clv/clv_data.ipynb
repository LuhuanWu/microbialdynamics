{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_clv(ndays, A, B, g, N):\n",
    "    \"\"\"Simulates data under compositional Lotka-Volterra.\n",
    "        \n",
    "        Let p = (p_1, ..., p_D) be the relative proportions\n",
    "        of D taxa (species).\n",
    "\n",
    "        Let x = alr(p), the additive log-ratio of p. Note \n",
    "        x is in R^{D-1} and p is in S^D.\n",
    "\n",
    "        The state space model is:\n",
    "            x_t ~ Normal(x_{t-1} + g + Ap_{t-1}, e)\n",
    "        \n",
    "        The observation model is:\n",
    "            y_t ~ Multinomial(C_t, p_t = alr^{-1}(x_t))\n",
    "\n",
    "        The count parameter C_t is chosen to simulate the\n",
    "        varying sequencing depths observed across real samples.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        ntaxa  : number of species to simulate\n",
    "        ndays  : number of days to simulate\n",
    "        ss_var : state space variance\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        x  : an ndays by ntaxa-1 matrix of latent states\n",
    "        y  : an ndays by ntaxa matrix of observed sequencing counts\n",
    "        A  : simulated interaction matrix A in R^{D-1 x D}\n",
    "        g  : simulated growth rate vector g in R^{D-1}\n",
    "        mu : initial mean\n",
    "\n",
    "    \"\"\"\n",
    "    latent_dim = A.shape[0]\n",
    "    input_dim = B.shape[1]\n",
    "    \n",
    "    x = []\n",
    "    y_count = []\n",
    "    y_percentage = []\n",
    "    v = []\n",
    "    \n",
    "    mu  = np.random.multivariate_normal(mean=np.zeros(latent_dim), cov=np.eye(latent_dim))\n",
    "    for t in range(ndays):\n",
    "        xt = mu\n",
    "\n",
    "        # increase dimension by 1\n",
    "        xt1 = np.concatenate((xt, np.array([0])))\n",
    "        pt = np.exp(xt1 - logsumexp(xt1))\n",
    "\n",
    "        # simulate total number of reads with over-dispersion\n",
    "        logN = np.random.normal(loc=np.log(N), scale=0.5)\n",
    "        Nt = np.random.poisson(np.exp(logN))\n",
    "        yt_count = np.random.multinomial(Nt, pt).astype(float)\n",
    "        yt_percentage = yt_count / np.sum(yt_count)\n",
    "        \n",
    "        vt = np.random.normal(loc=0,scale=0.1,size=input_dim)\n",
    "\n",
    "        x.append(xt)\n",
    "        y_count.append(yt_count)\n",
    "        y_percentage.append(yt_percentage)\n",
    "        v.append(vt)\n",
    "\n",
    "        transition_noise = np.random.multivariate_normal(mean=np.zeros(latent_dim), cov=0.1 * np.eye(latent_dim))\n",
    "        mu  = xt + g + A.dot(pt) + B.dot(vt) + transition_noise\n",
    "    return x, y_count, y_percentage, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntaxa = 11\n",
    "ninput = 15\n",
    "ndays = 50\n",
    "n_train, n_test = 200, 40\n",
    "A = np.random.normal(loc=0,scale=0.2,size=(ntaxa-1, ntaxa))\n",
    "B = np.random.normal(loc=0,scale=0.2,size=(ntaxa-1, ninput))\n",
    "g = np.random.normal(loc=0,scale=0.1,size=ntaxa-1)\n",
    "N = 10000 # sequencing reads parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_count_train = []\n",
    "y_count_test = []\n",
    "y_percentage_train = []\n",
    "y_percentage_test = []\n",
    "v_train = []\n",
    "v_test = []\n",
    "days = np.arange(ndays)[:, np.newaxis]\n",
    "for i in range(n_train + n_test):\n",
    "    x, y_count, y_percentage, v = simulate_clv(ndays, A, B, g, N)\n",
    "    x, y_count, y_percentage, v = np.asarray(x), np.asarray(y_count), np.asarray(y_percentage), np.asarray(v)\n",
    "    y_count = np.concatenate([days, y_count], axis=-1)\n",
    "    y_percentage = np.concatenate([days, y_percentage], axis=-1)\n",
    "    v = np.concatenate([days, v], axis=-1)\n",
    "    if i < n_train:\n",
    "        x_train.append(x)\n",
    "        y_count_train.append(y_count)\n",
    "        y_percentage_train.append(y_percentage)\n",
    "        v_train.append(v)\n",
    "    else:\n",
    "        x_test.append(x)\n",
    "        y_count_test.append(y_count)\n",
    "        y_percentage_test.append(y_percentage)\n",
    "        v_test.append(v)\n",
    "data_count_obs = {\"Xtrain\": x_train, \"Xtest\": x_test,\n",
    "                  \"Ytrain\": y_count_train, \"Ytest\": y_count_test,\n",
    "                  \"Vtrain\": v_train, \"Vtest\": v_test,\n",
    "                  \"A\": A, \"B\": B, \"g\": g, \"N\": N}\n",
    "data_percentage_obs = {\"Xtrain\": x_train, \"Xtest\": x_test,\n",
    "                       \"Ytrain\": y_percentage_train, \"Ytest\": y_percentage_test,\n",
    "                       \"Vtrain\": v_train, \"Vtest\": v_test,\n",
    "                       \"A\": A, \"B\": B, \"g\": g, \"N\": N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clv_count.p\", \"wb\") as f:\n",
    "    pickle.dump(data_count_obs, f)\n",
    "with open(\"clv_percentage.p\", \"wb\") as f:\n",
    "    pickle.dump(data_percentage_obs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = ndays\n",
    "for obs_percentage in [0.8, 0.6, 0.5, 0.4]:\n",
    "    y_count_train_tmp = []\n",
    "    y_count_test_tmp = []\n",
    "    y_percentage_train_tmp = []\n",
    "    y_percentage_test_tmp = []\n",
    "    for y_count, y_percentage in zip(y_count_train, y_percentage_train):\n",
    "        obsed_days = np.random.choice(np.arange(T), int(T * obs_percentage), replace=False)\n",
    "        obsed_days = np.sort(obsed_days)\n",
    "        y_count_train_tmp.append(y_count[obsed_days])\n",
    "        y_percentage_train_tmp.append(y_percentage[obsed_days])\n",
    "    for y_count, y_percentage in zip(y_count_test, y_percentage_test):\n",
    "        obsed_days = np.random.choice(np.arange(T), int(T * obs_percentage), replace=False)\n",
    "        obsed_days = np.sort(obsed_days)\n",
    "        y_count_test_tmp.append(y_count[obsed_days])\n",
    "        y_percentage_test_tmp.append(y_percentage[obsed_days])\n",
    "        \n",
    "    y_count_train_tmp = np.stack(y_count_train_tmp)\n",
    "    y_count_test_tmp = np.stack(y_count_test_tmp)\n",
    "    y_percentage_train_tmp = np.stack(y_percentage_train_tmp)\n",
    "    y_percentage_test_tmp = np.stack(y_percentage_test_tmp)\n",
    "    \n",
    "    data_count_obs = {\"Xtrain\": x_train, \"Xtest\": x_test,\n",
    "                      \"Ytrain\": y_count_train_tmp, \"Ytest\": y_count_test_tmp,\n",
    "                      \"Vtrain\": v_train, \"Vtest\": v_test,\n",
    "                      \"A\": A, \"B\": B, \"g\": g, \"N\": N}\n",
    "    data_percentage_obs = {\"Xtrain\": x_train, \"Xtest\": x_test,\n",
    "                           \"Ytrain\": y_percetage_train_tmp, \"Ytest\": y_percetage_test_tmp,\n",
    "                           \"Vtrain\": v_train, \"Vtest\": v_test,\n",
    "                           \"A\": A, \"B\": B, \"g\": g, \"N\": N}\n",
    "\n",
    "    with open(\"clv_count_{}_obs.p\".format(obs_percentage), \"wb\") as f:\n",
    "        pickle.dump(data_count_obs, f)\n",
    "    with open(\"clv_percentage_{}_obs.p\".format(obs_percentage), \"wb\") as f:\n",
    "        pickle.dump(data_percentage_obs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
