{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary input vector\n",
    "def simulate_single_input(time, Dv):\n",
    "    inputs = np.zeros((time, Dv))    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_clv_with_inputs(A, Wa, g, Wg, f_cov, N, inputs):\n",
    "    latent_dim = A.shape[0]\n",
    "    ndays, input_dim = inputs.shape\n",
    "    x = []\n",
    "    y_count = []\n",
    "    y_percentage = []\n",
    "\n",
    "    # modify the mu\n",
    "    mu = np.random.multivariate_normal(mean=np.zeros(latent_dim), cov=np.eye(latent_dim))\n",
    "    for t in range(ndays):\n",
    "        xt = mu\n",
    "\n",
    "        # increase dimension by 1\n",
    "        xt1 = np.concatenate((xt, np.array([0])))\n",
    "        pt = np.exp(xt1 - logsumexp(xt1))\n",
    "\n",
    "        # simulate total number of reads with over-dispersion\n",
    "        logN = np.random.normal(loc=np.log(N), scale=0.5)\n",
    "        Nt = np.random.poisson(np.exp(logN))\n",
    "        \n",
    "        yt_count = np.random.multinomial(Nt, pt).astype(float)\n",
    "        yt_percentage = yt_count / np.sum(yt_count)\n",
    "        \n",
    "        x.append(xt)\n",
    "        y_count.append(yt_count)\n",
    "        y_percentage.append(yt_percentage)\n",
    "        \n",
    "        transition_noise = np.random.multivariate_normal(mean=np.zeros(latent_dim), cov=np.diag(f_cov))\n",
    "        vt = inputs[t]\n",
    "\n",
    "        # Wg: (Dx, Dv), Wa: (Dx, Dv)\n",
    "        mu = xt + g + Wg.dot(vt) + (A + Wa.dot(vt)[:,None]).dot(pt) + transition_noise\n",
    "        mu = np.clip(mu, -5, 5)\n",
    "\n",
    "    return np.array(x), np.array(y_count), np.array(y_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ntaxa = 11\n",
    "ninput = 0  # including surgery\n",
    "n_train, n_test = 1800, 30\n",
    "time_min = 30\n",
    "time_max = 50\n",
    "scale = 1\n",
    "simulation_time = time_max * scale\n",
    "\n",
    "A  = np.random.normal(loc=0,    scale=0.05, size=(ntaxa - 1, ntaxa))\n",
    "g  = np.random.normal(loc=0,    scale=0.05, size=(ntaxa - 1,))\n",
    "Wa = np.random.normal(loc=0,    scale=0.0, size=(ntaxa - 1, ninput))\n",
    "Wg = np.random.normal(loc=-0.2, scale=0.2, size=(ntaxa - 1, ninput))\n",
    "f_cov = np.random.uniform(0, 1, ntaxa - 1)\n",
    "N = 10000 # sequencing reads parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_params = True\n",
    "if overwrite_params:\n",
    "    with open(\"data_no_input/clv_count_ntrain_600_Dx_10.p\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    A = d[\"A\"]\n",
    "    Wa = d[\"Wa\"]\n",
    "    Wg = d[\"Wg\"]\n",
    "    g = d[\"g\"]\n",
    "    f_cov = d[\"f_cov\"]\n",
    "    N = d[\"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data with missing observation\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_count_train = []\n",
    "y_count_test = []\n",
    "y_percentage_train = []\n",
    "y_percentage_test = []\n",
    "v_train = []\n",
    "v_test = []\n",
    "\n",
    "batch_inputs = [simulate_single_input(simulation_time, ninput) for _ in range(n_train + n_test)]\n",
    "\n",
    "for i in range(n_train + n_test):\n",
    "    v = batch_inputs[i]\n",
    "    x, y_count, y_percentage = simulate_clv_with_inputs(A, Wa, g, Wg, f_cov, N, v)\n",
    "\n",
    "    idx = np.arange(time_max) * scale\n",
    "    ndays = np.random.randint(time_min, time_max)\n",
    "    start = np.random.randint(time_max - ndays)\n",
    "    idx = idx[start:start + ndays]\n",
    "    \n",
    "    x = x[idx]\n",
    "    y_count = y_count[idx]\n",
    "    y_percentage = y_percentage[idx]\n",
    "    v = v[idx]\n",
    "    \n",
    "    # make missing observations, the first day cannot be missing\n",
    "    obs_percentage = np.random.choice([0.4,0.5,0.6,0.7,0.8], p=[0.1, 0.2, 0.2, 0.2, 0.3])\n",
    "    # obs_percentage = 0.999\n",
    "    obsed_days = np.random.choice(np.arange(1, ndays), int(ndays * obs_percentage), replace=False)\n",
    "    obsed_days = np.sort(np.concatenate(([0],obsed_days)))\n",
    "    \n",
    "    y_percentage = y_percentage[obsed_days]\n",
    "    x = x[obsed_days]\n",
    "    y_count = y_count[obsed_days]\n",
    "    \n",
    "    days = np.arange(ndays)[:, np.newaxis]\n",
    "    y_count = np.concatenate([days[obsed_days], y_count], axis=-1)\n",
    "    y_percentage = np.concatenate([days[obsed_days], y_percentage], axis=-1)\n",
    "    v = np.concatenate([days, v], axis=-1)\n",
    "    \n",
    "    if i < n_train:\n",
    "        x_train.append(x)\n",
    "        y_count_train.append(y_count)\n",
    "        y_percentage_train.append(y_percentage)\n",
    "        v_train.append(v)\n",
    "    else:\n",
    "        x_test.append(x)\n",
    "        y_count_test.append(y_count)\n",
    "        y_percentage_test.append(y_percentage)\n",
    "        v_test.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_train = []\n",
    "for single_obs in y_count_train:\n",
    "    single_counts = single_obs[:,1:].sum(axis=-1)\n",
    "    counts_train.append(single_counts)\n",
    "    \n",
    "counts_test = []\n",
    "for single_obs in y_count_test:\n",
    "    single_counts = single_obs[:,1:].sum(axis=-1)\n",
    "    counts_test.append(single_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = {}\n",
    "p_data[\"Xtrain\"] = x_train\n",
    "p_data[\"Xtest\"] = x_test\n",
    "p_data[\"Ytrain\"] = y_percentage_train\n",
    "p_data[\"Ytest\"] = y_percentage_test\n",
    "p_data[\"Vtrain\"] = v_train\n",
    "p_data[\"Vtest\"] = v_test\n",
    "\n",
    "p_data[\"A\"] = A\n",
    "p_data[\"Wa\"] = Wa\n",
    "p_data[\"g\"] = g\n",
    "p_data[\"Wg\"] = Wg\n",
    "p_data[\"f_cov\"] = f_cov\n",
    "p_data[\"N\"] = N\n",
    "with open(\"data_no_input/clv_ntrain_{}_Dx_{}.p\".format(n_train, ntaxa - 1), \"wb\") as f:\n",
    "    pickle.dump(p_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = {}\n",
    "c_data[\"Xtrain\"] = x_train\n",
    "c_data[\"Xtest\"] = x_test\n",
    "c_data[\"Ytrain\"] = y_count_train\n",
    "c_data[\"Ytest\"] = y_count_test\n",
    "c_data[\"Vtrain\"] = v_train\n",
    "c_data[\"Vtest\"] = v_test\n",
    "c_data[\"counts_train\"] = counts_train\n",
    "c_data[\"counts_test\"] = counts_test\n",
    "\n",
    "c_data[\"A\"] = A\n",
    "c_data[\"Wa\"] = Wa\n",
    "c_data[\"g\"] = g\n",
    "c_data[\"Wg\"] = Wg\n",
    "c_data[\"f_cov\"] = f_cov\n",
    "c_data[\"N\"] = N\n",
    "with open(\"data_no_input/clv_count_ntrain_{}_Dx_{}.p\".format(n_train, ntaxa - 1), \"wb\") as f:\n",
    "    pickle.dump(c_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data_interpolation import interpolate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_train, hidden_test, obs_train, obs_test, input_train, input_test = x_train, x_test, y_percentage_train, y_percentage_test, v_train, v_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_inputs_train = [None for _ in range(len(obs_train))]\n",
    "extra_inputs_test = [None for _ in range(len(obs_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_train, hidden_test, obs_train, obs_test, input_train, input_test, _mask_train, _mask_test, time_interval_train, time_interval_test, extra_inputs_train, extra_input_test = \\\n",
    "                interpolate_data(hidden_train, hidden_test, obs_train, obs_test, input_train, input_test,\n",
    "                                 extra_inputs_train, extra_inputs_test, False)\n",
    "\n",
    "\n",
    "masks = _mask_train + _mask_test\n",
    "obs = obs_train + obs_test\n",
    "inputs = input_train + input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count data\n",
    "c_hidden_train, c_hidden_test, c_obs_train, c_obs_test, c_input_train, c_input_test, c_extra_inputs_train, c_extra_inputs_test = x_train, x_test, y_count_train, y_count_test, v_train, v_test, counts_train, counts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_hidden_train, c_hidden_test, c_obs_train, c_obs_test, c_input_train, c_input_test, c_mask_train, c_mask_test, time_interval_train, time_interval_test, c_extra_inputs_train, c_extra_input_test = \\\n",
    "                interpolate_data(c_hidden_train, c_hidden_test, c_obs_train, c_obs_test, c_input_train, c_input_test,\n",
    "                                 c_extra_inputs_train, c_extra_inputs_test, False)\n",
    "\n",
    "\n",
    "c_masks = c_mask_train + c_mask_test\n",
    "c_obs = c_obs_train + c_obs_test\n",
    "c_inputs = c_input_train + c_input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(ax, obs, mask, to_normalize=True):\n",
    "    if to_normalize:\n",
    "            obs = obs / np.sum(obs, axis=-1, keepdims=True)\n",
    "\n",
    "    time, Dy = obs.shape\n",
    "\n",
    "    # make missing obs = 0\n",
    "    masked_obs = np.zeros_like(obs)\n",
    "    masked_obs[mask] = obs[mask]\n",
    "    \n",
    "    ax.set_xlabel(\"Time\")\n",
    "    bottom = np.zeros(time)\n",
    "    for j in range(Dy):\n",
    "        ax.bar(np.arange(time), masked_obs[:, j], bottom=bottom, edgecolor='white')\n",
    "        bottom += masked_obs[:, j]\n",
    "\n",
    "    ax.set_xticks(np.arange(time))\n",
    "    sns.despine()\n",
    "    \n",
    "\n",
    "def input_plot(ax, inputs):\n",
    "    time, Dv = inputs.shape\n",
    "    \n",
    "    for j in range(Dv):\n",
    "        has_inputs = inputs[:,j]== 1\n",
    "        idx = np.arange(time)[has_inputs]\n",
    "        ax.bar(idx, [1 for _ in idx], bottom=[j for _ in idx], color='blue')\n",
    "    \n",
    "    ax.set_xticks(np.arange(time))\n",
    "    ax.set_yticks(np.arange(Dv))\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inputs_and_obs(inputs, masks, i, to_normalize=True):\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    ax1= plt.subplot(2,1,1)\n",
    "    input_plot(ax1, inputs[i])\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2 = plt.subplot(2,1,2, sharex = ax1)\n",
    "    bar_plot(ax2, obs[i], masks[i], to_normalize=to_normalize)\n",
    "    ax2.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plot_inputs_and_obs(inputs, masks, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inputs_and_obs(c_inputs, c_masks, 10, to_normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
